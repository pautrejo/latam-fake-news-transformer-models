{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f15f812",
   "metadata": {},
   "source": [
    "# Inference\n",
    "This notebook is used to make predictions on unlabeled datasets. We will evaluate the performance on new unseen data. The results of the comparison will help to determine which model is most suitable for the task at hand and to improve the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e691f294",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd51b2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de57cbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pautrejo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import unidecode\n",
    "import timeit\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "#lemmatizer\n",
    "import spacy\n",
    "import spacy_spanish_lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7927ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install spacy_spanish_lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb1e3fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-lg==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_lg-3.4.0/es_core_news_lg-3.4.0-py3-none-any.whl (568.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.0/568.0 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from es-core-news-lg==3.4.0) (3.4.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (1.24.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (1.10.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (1.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (8.1.5)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (3.1.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (3.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (2.4.5)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (0.7.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (2.28.1)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (58.1.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (2.0.7)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (21.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (6.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (3.0.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (3.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->es-core-news-lg==3.4.0) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_lg')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download es_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d6265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c8280ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertModel,BertTokenizer,BertForSequenceClassification,AutoTokenizer,AutoModelForSequenceClassification,Trainer, RobertaConfig,RobertaForSequenceClassification,ElectraConfig,ElectraForSequenceClassification\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1b6a0",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "1. business_disaggregated.json\n",
    "2. twitter_disaggregated.json\n",
    "3.  profiles_disaggregated.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adbcaf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('inference/business_disaggregated.json')\n",
    "df2 = pd.read_json('inference/twitter_disaggregated.json')\n",
    "df3 = pd.read_json('inference/profiles_disaggregated.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa0ff0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_post</th>\n",
       "      <th>link_post</th>\n",
       "      <th>facebook_page</th>\n",
       "      <th>date_post</th>\n",
       "      <th>social_platform</th>\n",
       "      <th>responseid</th>\n",
       "      <th>before_june27</th>\n",
       "      <th>june27_july14</th>\n",
       "      <th>after_july14</th>\n",
       "      <th>period</th>\n",
       "      <th>text</th>\n",
       "      <th>image_text</th>\n",
       "      <th>words_post</th>\n",
       "      <th>dummy_image</th>\n",
       "      <th>dummy_video</th>\n",
       "      <th>total_likes</th>\n",
       "      <th>total_comments</th>\n",
       "      <th>total_shares</th>\n",
       "      <th>total_reactions</th>\n",
       "      <th>total_interactions</th>\n",
       "      <th>dummy_external_website</th>\n",
       "      <th>dummy_external_article</th>\n",
       "      <th>dummy_working_newspaper</th>\n",
       "      <th>dummy_factchecking</th>\n",
       "      <th>dummy_misinformation_report</th>\n",
       "      <th>dummy_verification_post</th>\n",
       "      <th>id_external_article</th>\n",
       "      <th>link_external_article</th>\n",
       "      <th>newspaper_external_article</th>\n",
       "      <th>feat_ner</th>\n",
       "      <th>count_organizations</th>\n",
       "      <th>count_persons</th>\n",
       "      <th>count_locations</th>\n",
       "      <th>count_pronouns</th>\n",
       "      <th>count_verbs</th>\n",
       "      <th>prop_organizations</th>\n",
       "      <th>prop_persons</th>\n",
       "      <th>prop_locations</th>\n",
       "      <th>prop_pronouns</th>\n",
       "      <th>prop_verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1ee1df9c-e2be-37f2-b38d-f5e8d868a127</td>\n",
       "      <td>https://www.facebook.com/MuyWaso/posts/7602809...</td>\n",
       "      <td>MuyWaso</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>facebook_pages</td>\n",
       "      <td>R_3KXQD4IH5RCGSWN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>post_treatment</td>\n",
       "      <td>¡Qué vivan las pibas!</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>162</td>\n",
       "      <td>354</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0.0, 0.25, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c17f3834-b466-3e42-bbdb-5ec57afbbfd7</td>\n",
       "      <td>https://www.facebook.com/MuyWaso/posts/7598045...</td>\n",
       "      <td>MuyWaso</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>facebook_pages</td>\n",
       "      <td>R_3KXQD4IH5RCGSWN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>post_treatment</td>\n",
       "      <td>Una demanda histórica del feminismo argentino ...</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>62</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76918f66-6f33-34e2-907a-5a4ba187e33c</td>\n",
       "      <td>https://muywaso.com/argentina-vive-una-jornada...</td>\n",
       "      <td>muywaso</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0.02, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1d29238-020f-3b85-b565-aefe994613aa</td>\n",
       "      <td>https://www.facebook.com/MuyWaso/posts/7555438...</td>\n",
       "      <td>MuyWaso</td>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>facebook_pages</td>\n",
       "      <td>R_3KXQD4IH5RCGSWN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>post_treatment</td>\n",
       "      <td>¡Ya dejen de hablar de 'Rompan todo', chiques!...</td>\n",
       "      <td>None</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>d68b17ab-9a47-3bc9-b542-c00327863a89</td>\n",
       "      <td>https://muywaso.com/10-bandas-de-cumbia-bolivi...</td>\n",
       "      <td>muywaso</td>\n",
       "      <td>[0, 0, 2, 0, 0, 0.0, 0.0, 0.0714285714, 0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e81f9634-e2f1-3dfd-8215-7bb3a1997610</td>\n",
       "      <td>https://www.facebook.com/MuyWaso/posts/7555082...</td>\n",
       "      <td>MuyWaso</td>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>facebook_pages</td>\n",
       "      <td>R_3KXQD4IH5RCGSWN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>post_treatment</td>\n",
       "      <td>Todxs dicen 'Rompan todo' esto, Santaolalla aq...</td>\n",
       "      <td>None</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6e057cd0-ad7c-39ae-b9a3-b41902f2aff1</td>\n",
       "      <td>https://muywaso.com/10-bandas-bolivianas-iconi...</td>\n",
       "      <td>muywaso</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0.0, 0.0344827586, 0.034482758...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bde7ceab-7c89-3690-b141-2e2b7b740bd8</td>\n",
       "      <td>https://www.facebook.com/MuyWaso/posts/7537784...</td>\n",
       "      <td>MuyWaso</td>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>facebook_pages</td>\n",
       "      <td>R_3KXQD4IH5RCGSWN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>post_treatment</td>\n",
       "      <td>El mejor periodismo posible se toma 'seco hast...</td>\n",
       "      <td>None</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 1, 1, 0, 0, 0.0, 0.0217391304, 0.021739130...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id_post  \\\n",
       "0  1ee1df9c-e2be-37f2-b38d-f5e8d868a127   \n",
       "1  c17f3834-b466-3e42-bbdb-5ec57afbbfd7   \n",
       "2  f1d29238-020f-3b85-b565-aefe994613aa   \n",
       "3  e81f9634-e2f1-3dfd-8215-7bb3a1997610   \n",
       "4  bde7ceab-7c89-3690-b141-2e2b7b740bd8   \n",
       "\n",
       "                                           link_post facebook_page  \\\n",
       "0  https://www.facebook.com/MuyWaso/posts/7602809...       MuyWaso   \n",
       "1  https://www.facebook.com/MuyWaso/posts/7598045...       MuyWaso   \n",
       "2  https://www.facebook.com/MuyWaso/posts/7555438...       MuyWaso   \n",
       "3  https://www.facebook.com/MuyWaso/posts/7555082...       MuyWaso   \n",
       "4  https://www.facebook.com/MuyWaso/posts/7537784...       MuyWaso   \n",
       "\n",
       "    date_post social_platform         responseid  before_june27  \\\n",
       "0  2020-12-30  facebook_pages  R_3KXQD4IH5RCGSWN              0   \n",
       "1  2020-12-29  facebook_pages  R_3KXQD4IH5RCGSWN              0   \n",
       "2  2020-12-21  facebook_pages  R_3KXQD4IH5RCGSWN              0   \n",
       "3  2020-12-21  facebook_pages  R_3KXQD4IH5RCGSWN              0   \n",
       "4  2020-12-18  facebook_pages  R_3KXQD4IH5RCGSWN              0   \n",
       "\n",
       "   june27_july14  after_july14          period  \\\n",
       "0              0             1  post_treatment   \n",
       "1              0             1  post_treatment   \n",
       "2              0             1  post_treatment   \n",
       "3              0             1  post_treatment   \n",
       "4              0             1  post_treatment   \n",
       "\n",
       "                                                text image_text  words_post  \\\n",
       "0                              ¡Qué vivan las pibas!       None           4   \n",
       "1  Una demanda histórica del feminismo argentino ...       None          50   \n",
       "2  ¡Ya dejen de hablar de 'Rompan todo', chiques!...       None          28   \n",
       "3  Todxs dicen 'Rompan todo' esto, Santaolalla aq...       None          29   \n",
       "4  El mejor periodismo posible se toma 'seco hast...       None          46   \n",
       "\n",
       "   dummy_image  dummy_video  total_likes  total_comments  total_shares  \\\n",
       "0            0            0          155               1            36   \n",
       "1            0            0           90               0             9   \n",
       "2            0            0           60               9            31   \n",
       "3            0            0           81               4            57   \n",
       "4            0            0           38               0             6   \n",
       "\n",
       "   total_reactions total_interactions  dummy_external_website  \\\n",
       "0              162                354                       1   \n",
       "1               62                161                       1   \n",
       "2               27                127                       1   \n",
       "3               53                195                       1   \n",
       "4               19                 63                       0   \n",
       "\n",
       "   dummy_external_article  dummy_working_newspaper  dummy_factchecking  \\\n",
       "0                       0                      NaN                 0.0   \n",
       "1                       1                      1.0                 0.0   \n",
       "2                       1                      1.0                 0.0   \n",
       "3                       1                      1.0                 0.0   \n",
       "4                       0                      NaN                 NaN   \n",
       "\n",
       "   dummy_misinformation_report  dummy_verification_post  \\\n",
       "0                            0                      0.0   \n",
       "1                            0                      0.0   \n",
       "2                            0                      0.0   \n",
       "3                            0                      0.0   \n",
       "4                            0                      0.0   \n",
       "\n",
       "                    id_external_article  \\\n",
       "0                                  None   \n",
       "1  76918f66-6f33-34e2-907a-5a4ba187e33c   \n",
       "2  d68b17ab-9a47-3bc9-b542-c00327863a89   \n",
       "3  6e057cd0-ad7c-39ae-b9a3-b41902f2aff1   \n",
       "4                                  None   \n",
       "\n",
       "                               link_external_article  \\\n",
       "0                                               None   \n",
       "1  https://muywaso.com/argentina-vive-una-jornada...   \n",
       "2  https://muywaso.com/10-bandas-de-cumbia-bolivi...   \n",
       "3  https://muywaso.com/10-bandas-bolivianas-iconi...   \n",
       "4                                               None   \n",
       "\n",
       "  newspaper_external_article  \\\n",
       "0                       None   \n",
       "1                    muywaso   \n",
       "2                    muywaso   \n",
       "3                    muywaso   \n",
       "4                       None   \n",
       "\n",
       "                                            feat_ner  count_organizations  \\\n",
       "0          [0, 1, 0, 0, 0, 0.0, 0.25, 0.0, 0.0, 0.0]                  0.0   \n",
       "1          [1, 0, 0, 0, 0, 0.02, 0.0, 0.0, 0.0, 0.0]                  1.0   \n",
       "2  [0, 0, 2, 0, 0, 0.0, 0.0, 0.0714285714, 0.0, 0.0]                  0.0   \n",
       "3  [0, 1, 1, 1, 1, 0.0, 0.0344827586, 0.034482758...                  0.0   \n",
       "4  [0, 1, 1, 0, 0, 0.0, 0.0217391304, 0.021739130...                  0.0   \n",
       "\n",
       "   count_persons  count_locations  count_pronouns  count_verbs  \\\n",
       "0            1.0              0.0             0.0          0.0   \n",
       "1            0.0              0.0             0.0          0.0   \n",
       "2            0.0              2.0             0.0          0.0   \n",
       "3            1.0              1.0             1.0          1.0   \n",
       "4            1.0              1.0             0.0          0.0   \n",
       "\n",
       "   prop_organizations  prop_persons  prop_locations  prop_pronouns  prop_verbs  \n",
       "0                0.00      0.250000        0.000000       0.000000    0.000000  \n",
       "1                0.02      0.000000        0.000000       0.000000    0.000000  \n",
       "2                0.00      0.000000        0.071429       0.000000    0.000000  \n",
       "3                0.00      0.034483        0.034483       0.034483    0.034483  \n",
       "4                0.00      0.021739        0.021739       0.000000    0.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6cfc8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188569, 40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f50798",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b21c4f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48055, 43)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9736cc91",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2028610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(sentence):\n",
    "  TAG_RE = re.compile(r'<[^>]+>')\n",
    "  sentence = TAG_RE.sub('',sentence)  # html tags\n",
    "  sentence = re.sub(r'https?:\\/\\/\\S*', '', sentence) # http links\n",
    "  sentence = re.sub(r'www\\.\\S*', '', sentence) # www links\n",
    "  sentence = re.sub(r'\\S+\\.com\\S+', '', sentence) # .com links\n",
    "  sentence = unidecode.unidecode(sentence)   \n",
    "  sentence = sentence.lower() #minus\n",
    "  sentence = re.sub(r'\\@\\S+', ' ', sentence) # @loQueSea\n",
    "  sentence = re.sub(r'\\#\\S+', ' ', sentence) # #hasthtags\n",
    "  sentence = re.sub('[^a-zA-Z]', ' ', sentence)  # punctuations and numbers\n",
    "  new_stopwords = set(stopwords.words('spanish')) - {'no'} #stopwords + no\n",
    "  sentence = ' '.join([word for word in sentence.split() if word not in new_stopwords]) #stopwords\n",
    "  sentence = re.sub(r'\\s+', ' ', sentence) # multiple space\n",
    "  sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence) # single character ' a '\n",
    "  sentence = re.sub(r\"^[a-zA-Z]\\s+\", ' ', sentence) #'a '\n",
    "  sentence = re.sub(r'\\b\\w{1,1}\\b', '', sentence)\n",
    "\n",
    "\n",
    "\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b9ad2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1u = pd.DataFrame(df1.text.drop_duplicates().dropna())\n",
    "df2u  = pd.DataFrame(df2.text.drop_duplicates().dropna())\n",
    "df3u  = pd.DataFrame(df3.text.drop_duplicates().dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f041936",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1u['texto_clean'] = df1u.text.map(lambda x: clean_text(x))\n",
    "df2u['texto_clean'] = df2u.text.map(lambda x: clean_text(x))\n",
    "df3u['texto_clean'] = df3u.text.map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b83dcfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coronavirus,covid\n",
    "df1u.texto_clean = df1u.texto_clean.str.replace('coronavirus','covid')\n",
    "df2u.texto_clean = df2u.texto_clean.str.replace('coronavirus','covid')\n",
    "df3u.texto_clean = df3u.texto_clean.str.replace('coronavirus','covid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8780c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemantizar(sentence):\n",
    "\n",
    "  doc = nlp(sentence)\n",
    "  sentence = ' '.join([token.lemma_ for token in doc]) # lemmatizer\n",
    "  new_stopwords = stopwords.words('spanish')  \n",
    "  sentence = ' '.join([word for word in sentence.split() if word not in new_stopwords]) #stopwords  \n",
    "  sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence) # single character ' a '\n",
    "  sentence = re.sub(r\"^[a-zA-Z]\\s+\", ' ', sentence) #'a '\n",
    "  sentence = re.sub(r'\\s+', ' ', sentence) # multiple space\n",
    "\n",
    "  return sentence  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3c98438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1u['texto_lem_spacy'] = df1u.texto_clean.map(lambda x: lemantizar(x)) \n",
    "df2u['texto_lem_spacy'] = df2u.texto_clean.map(lambda x: lemantizar(x)) \n",
    "df3u['texto_lem_spacy'] = df3u.texto_clean.map(lambda x: lemantizar(x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d398dd",
   "metadata": {},
   "source": [
    "Length of posts during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9886a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1u = df1u[df1u['texto_lem_spacy'].str.split().str.len()>2]\n",
    "df2u = df2u[df2u['texto_lem_spacy'].str.split().str.len()>2]\n",
    "df3u = df3u[df3u['texto_lem_spacy'].str.split().str.len()>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "54a5595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1u = df1u[df1u['texto_lem_spacy'].str.len()<=512]\n",
    "df2u = df2u[df2u['texto_lem_spacy'].str.len()<=512]\n",
    "df3u = df3u[df3u['texto_lem_spacy'].str.len()<=512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "60ced7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118060, 3)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ae4b06ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54403, 3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4f912f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13540, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "75be558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1u.to_csv('inference1.csv',index=False)\n",
    "df2u.to_csv('inference2.csv',index=False)\n",
    "df3u.to_csv('inference3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d3b354",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c04fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1u = pd.read_csv('inference1.csv')\n",
    "df2u = pd.read_csv('inference2.csv')\n",
    "df3u = pd.read_csv('inference3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866c5eb7",
   "metadata": {},
   "source": [
    "## BETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d469664",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_name = 'config.json'\n",
    "model_name = 'pytorch_model.bin'\n",
    "conf = f'/Beto_model/{conf_name}'\n",
    "model = f'/Beto_model/{model_name}'\n",
    "\n",
    "config = BertConfig.from_json_file(conf)\n",
    "beto = BertForSequenceClassification.from_pretrained(model, config = config )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased',truncation=True, padding=True)\n",
    "clf = pipeline('text-classification', model=beto, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77ec8a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4769.88846229203\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "pred_1 = clf(list(df1u.texto_lem_spacy.values))\n",
    "end = timeit.default_timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f58a392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1968.800096000079\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "pred_2 = clf(list(df2u.texto_lem_spacy.values))\n",
    "end = timeit.default_timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "99eb0956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498.3062792918645\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "pred_3 = clf(list(df3u.texto_lem_spacy.values))\n",
    "end = timeit.default_timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c908d55d",
   "metadata": {},
   "source": [
    "Auxiliar function to save results in correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f66aa0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(df,pred,model):\n",
    "    label = 'label_' + model\n",
    "    res = []\n",
    "    for i in range(df.shape[0]):\n",
    "        res.append(pred[i]['label'])\n",
    "    df[label] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "38d4014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label(df1u,pred_1,'beto')\n",
    "label(df2u,pred_2,'beto')\n",
    "label(df3u,pred_3,'beto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f7007cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL_1    67151\n",
       "LABEL_0    50909\n",
       "Name: label_beto, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1u.label_beto.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e148d38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL_0    33467\n",
       "LABEL_1    20936\n",
       "Name: label_beto, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2u.label_beto.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f24009c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL_1    7192\n",
       "LABEL_0    6348\n",
       "Name: label_beto, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3u.label_beto.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "afc6f7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>texto_clean</th>\n",
       "      <th>texto_lem_spacy</th>\n",
       "      <th>label_beto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Coronavirus #Educación #Salud #Bolivia  El Mi...</td>\n",
       "      <td>ministerio educacion aprobo descuento pensione...</td>\n",
       "      <td>ministerio educacion aprobo descuento pensión ...</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#Salud #Bolivia #Coronavirus Este miércoles 24...</td>\n",
       "      <td>miercoles junio bolivia registro nuevos casos ...</td>\n",
       "      <td>miercol junio bolivia registro nuevo caso sumo...</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Salud #Coronavirus #ElAlto El Hospital Bolivi...</td>\n",
       "      <td>hospital boliviano holandes ciudad alto determ...</td>\n",
       "      <td>hospital boliviano holandes ciudad alto determ...</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Salud #Bolivia #Coronavirus El Centro Naciona...</td>\n",
       "      <td>centro nacional enfermedades tropicales santa ...</td>\n",
       "      <td>centro nacional enfermedad tropical santa cruz...</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Salud #Coronavirus #Bolivia En Santa Cruz, Be...</td>\n",
       "      <td>santa cruz beni cochabamba entierran personas ...</td>\n",
       "      <td>santa cruz beni cochabamba enterrar persona fa...</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13535</th>\n",
       "      <td>Gracias por ser una maquina de memes</td>\n",
       "      <td>gracias ser maquina memes</td>\n",
       "      <td>gracia ser maquina mem</td>\n",
       "      <td>LABEL_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13536</th>\n",
       "      <td>Puro Fortnite Compa</td>\n",
       "      <td>puro fortnite compa</td>\n",
       "      <td>puro fortnite compa</td>\n",
       "      <td>LABEL_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13537</th>\n",
       "      <td>Erick Peñaloza siempre llevandote a la victoria</td>\n",
       "      <td>erick penaloza siempre llevandote victoria</td>\n",
       "      <td>erick penaloza siempre llevandote victoria</td>\n",
       "      <td>LABEL_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13538</th>\n",
       "      <td>El chiste se cuenta solo</td>\n",
       "      <td>chiste cuenta solo</td>\n",
       "      <td>chiste contar solo</td>\n",
       "      <td>LABEL_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13539</th>\n",
       "      <td>Videos mal editados de bailes pero que dan ris...</td>\n",
       "      <td>videos mal editados bailes dan risa</td>\n",
       "      <td>video mal editado baile dar risa</td>\n",
       "      <td>LABEL_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13540 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      #Coronavirus #Educación #Salud #Bolivia  El Mi...   \n",
       "1      #Salud #Bolivia #Coronavirus Este miércoles 24...   \n",
       "2      #Salud #Coronavirus #ElAlto El Hospital Bolivi...   \n",
       "3      #Salud #Bolivia #Coronavirus El Centro Naciona...   \n",
       "4      #Salud #Coronavirus #Bolivia En Santa Cruz, Be...   \n",
       "...                                                  ...   \n",
       "13535              Gracias por ser una maquina de memes    \n",
       "13536                                Puro Fortnite Compa   \n",
       "13537   Erick Peñaloza siempre llevandote a la victoria    \n",
       "13538                           El chiste se cuenta solo   \n",
       "13539  Videos mal editados de bailes pero que dan ris...   \n",
       "\n",
       "                                             texto_clean  \\\n",
       "0      ministerio educacion aprobo descuento pensione...   \n",
       "1      miercoles junio bolivia registro nuevos casos ...   \n",
       "2      hospital boliviano holandes ciudad alto determ...   \n",
       "3      centro nacional enfermedades tropicales santa ...   \n",
       "4      santa cruz beni cochabamba entierran personas ...   \n",
       "...                                                  ...   \n",
       "13535                          gracias ser maquina memes   \n",
       "13536                                puro fortnite compa   \n",
       "13537         erick penaloza siempre llevandote victoria   \n",
       "13538                                 chiste cuenta solo   \n",
       "13539               videos mal editados bailes dan risa    \n",
       "\n",
       "                                         texto_lem_spacy label_beto  \n",
       "0      ministerio educacion aprobo descuento pensión ...    LABEL_1  \n",
       "1      miercol junio bolivia registro nuevo caso sumo...    LABEL_1  \n",
       "2      hospital boliviano holandes ciudad alto determ...    LABEL_1  \n",
       "3      centro nacional enfermedad tropical santa cruz...    LABEL_1  \n",
       "4      santa cruz beni cochabamba enterrar persona fa...    LABEL_1  \n",
       "...                                                  ...        ...  \n",
       "13535                             gracia ser maquina mem    LABEL_0  \n",
       "13536                                puro fortnite compa    LABEL_0  \n",
       "13537         erick penaloza siempre llevandote victoria    LABEL_0  \n",
       "13538                                 chiste contar solo    LABEL_0  \n",
       "13539                   video mal editado baile dar risa    LABEL_0  \n",
       "\n",
       "[13540 rows x 4 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3a2b99",
   "metadata": {},
   "source": [
    "## BERT multilingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0af8ad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_name = 'config.json'\n",
    "model_name = 'pytorch_model.bin'\n",
    "conf = f'/Bertmulti_model/{conf_name}'\n",
    "model = f'/Bertmulti_model/{model_name}'\n",
    "\n",
    "config = BertConfig.from_json_file(conf)\n",
    "bert = BertForSequenceClassification.from_pretrained(model, config = config )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-uncased',truncation=True, padding=True)\n",
    "clf = pipeline('text-classification', model=bert, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c0481ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4173.350183833158\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "pred_1b = clf(list(df1u.texto_lem_spacy.values))\n",
    "end = timeit.default_timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a2aa334e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1845.1252629999071\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "pred_2b = clf(list(df2u.texto_lem_spacy.values))\n",
    "end = timeit.default_timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "761e690a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502.1237917919643\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "pred_3b = clf(list(df3u.texto_lem_spacy.values))\n",
    "end = timeit.default_timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "23c78063",
   "metadata": {},
   "outputs": [],
   "source": [
    "label(df1u,pred_1b,'bert_multi')\n",
    "label(df2u,pred_2b,'bert_multi')\n",
    "label(df3u,pred_3b,'bert_multi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2d6999",
   "metadata": {},
   "source": [
    "## BERTin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c60c5909",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_name = 'config.json'\n",
    "model_name = 'pytorch_model.bin'\n",
    "conf = f'/Users/pautrejo/Documents/ITAM/Estancia/Bertin_model/{conf_name}'\n",
    "model = f'/Users/pautrejo/Documents/ITAM/Estancia/Bertin_model/{model_name}'\n",
    "\n",
    "config = RobertaConfig.from_json_file(conf)\n",
    "bertin = RobertaForSequenceClassification.from_pretrained(model, config = config )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bertin-project/bertin-roberta-base-spanish',truncation=True, padding=True)\n",
    "clf = pipeline('text-classification', model=bertin, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "aea8e3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4068.515656792093\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "pred_1bb = clf(list(df1u.texto_lem_spacy.values))\n",
    "end = timeit.default_timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8dc383f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1804.2637675420847\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "pred_2bb = clf(list(df2u.texto_lem_spacy.values))\n",
    "end = timeit.default_timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8e1962a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499.3272417089902\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "pred_3bb = clf(list(df3u.texto_lem_spacy.values))\n",
    "end = timeit.default_timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5128079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label(df1u,pred_1bb,'bertin')\n",
    "label(df2u,pred_2bb,'bertin')\n",
    "label(df3u,pred_3bb,'bertin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6d7138",
   "metadata": {},
   "source": [
    "## ELECTRicidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "474cc9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_name = 'config.json'\n",
    "model_name = 'pytorch_model.bin'\n",
    "conf = f'/Users/pautrejo/Documents/ITAM/Estancia/electricidad_model/{conf_name}'\n",
    "model = f'/Users/pautrejo/Documents/ITAM/Estancia/electricidad_model/{model_name}'\n",
    "\n",
    "config = ElectraConfig.from_json_file(conf)\n",
    "electr = ElectraForSequenceClassification.from_pretrained(model, config = config )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('mrm8488/electricidad-base-discriminator',truncation=True, padding=True)\n",
    "clf = pipeline('text-classification', model=electr, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5680142b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4320.480115083046\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "pred_1e = clf(list(df1u.texto_lem_spacy.values))\n",
    "end = timeit.default_timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f84aa628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4580.363040333032\n"
     ]
    }
   ],
   "source": [
    "#2nd try\n",
    "start = timeit.default_timer()\n",
    "pred_1e = clf(list(df1.texto_lem_spacy.values))\n",
    "end = timeit.default_timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "309d2bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1928.0979319580365\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "pred_2e = clf(list(df2u.texto_lem_spacy.values))\n",
    "end = timeit.default_timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4a8fe695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490.27749512484297\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "pred_3e = clf(list(df3u.texto_lem_spacy.values))\n",
    "end = timeit.default_timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "76ef95ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "label(df1u,pred_1e,'electra')\n",
    "label(df2u,pred_2e,'electra')\n",
    "label(df3u,pred_3e,'electra')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225ba4b",
   "metadata": {},
   "source": [
    "## sELECTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14047bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_name = 'config.json'\n",
    "model_name = 'pytorch_model.bin'\n",
    "conf = f'/Users/pautrejo/Documents/ITAM/Estancia/selectra_model/{conf_name}'\n",
    "model = f'/Users/pautrejo/Documents/ITAM/Estancia/selectra_model/{model_name}'\n",
    "\n",
    "config = ElectraConfig.from_json_file(conf)\n",
    "selectr = ElectraForSequenceClassification.from_pretrained(model, config = config )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('Recognai/selectra_small',truncation=True, padding=True)\n",
    "clf = pipeline('text-classification', model=selectr, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a3c601f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "989.7366086249822\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "pred_1e = clf(list(df1.texto_lem_spacy.values))\n",
    "end = timeit.default_timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7973088d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405.00856841600034\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "pred_2e = clf(list(df2.texto_lem_spacy.values))\n",
    "end = timeit.default_timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e70b971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109.80361233395524\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "pred_3e = clf(list(df3.texto_lem_spacy.values))\n",
    "end = timeit.default_timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09f0db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "label(df1,pred_1e,'selectra')\n",
    "label(df2,pred_2e,'selectra')\n",
    "label(df3,pred_3e,'selectra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "921351c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL_0    64042\n",
       "LABEL_1    54018\n",
       "Name: label_selectra, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.label_selectra.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8895eb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL_0    42502\n",
       "LABEL_1    11901\n",
       "Name: label_selectra, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.label_selectra.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b444be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL_0    8090\n",
       "LABEL_1    5450\n",
       "Name: label_selectra, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.label_selectra.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0eac93",
   "metadata": {},
   "source": [
    "Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dea8560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('inference1_res.csv',index=False)\n",
    "df2.to_csv('inference2_res.csv',index=False)\n",
    "df3.to_csv('inference3_res.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3edd64e",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a1d4ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>texto_clean</th>\n",
       "      <th>texto_lem_spacy</th>\n",
       "      <th>label_beto</th>\n",
       "      <th>label_bert_multi</th>\n",
       "      <th>label_bertin</th>\n",
       "      <th>label_electra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Una demanda histórica del feminismo argentino ...</td>\n",
       "      <td>demanda historica feminismo argentino podria c...</td>\n",
       "      <td>demanda historico feminismo argentino podria c...</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¡Ya dejen de hablar de 'Rompan todo', chiques!...</td>\n",
       "      <td>dejen hablar rompan chiques mejor discutamos s...</td>\n",
       "      <td>dejar hablar romper chiques mejor discutar sel...</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Todxs dicen 'Rompan todo' esto, Santaolalla aq...</td>\n",
       "      <td>todxs dicen rompan santaolalla aquello netflix...</td>\n",
       "      <td>todxs decir romper santaolalla aquel netflix n...</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El mejor periodismo posible se toma 'seco hast...</td>\n",
       "      <td>mejor periodismo posible toma seco fondo sorbi...</td>\n",
       "      <td>mejor periodismo posible tomar seco fondo sorb...</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mayerlín se cruzó con una doctora que corrió c...</td>\n",
       "      <td>mayerlin cruzo doctora corrio gastos internaci...</td>\n",
       "      <td>mayerlin cruzo doctora corrio gastos internaci...</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118055</th>\n",
       "      <td>#AGROnoticias SECTOR AGRÍCOLA BUSCA QUE SUS TI...</td>\n",
       "      <td>sector agricola busca tierras objeto creditos ...</td>\n",
       "      <td>sector agricola buscar tierra objeto creditos ...</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118056</th>\n",
       "      <td>#AGROnoticias El país produce 3 mil T de manza...</td>\n",
       "      <td>pais produce mil manzana importa mil argentina...</td>\n",
       "      <td>pais producir mil manzana importar mil argenti...</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118057</th>\n",
       "      <td>𝗣𝗟𝗔𝗡𝗜𝗙𝗜𝗖𝗔 𝗧𝗨 𝗦𝗘𝗠𝗔𝗡𝗔 𝗝𝗨𝗡𝗧𝗢 𝗔𝗟 #AGROboletin 𝗖𝗟𝗜𝗠...</td>\n",
       "      <td>planifica semana junto clima precios mercados ...</td>\n",
       "      <td>planificar semana junto clima precio mercado l...</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118058</th>\n",
       "      <td>¡𝗣𝗢𝗥𝗤𝗨𝗘́ 𝗦𝗢𝗠𝗢𝗦 𝗟𝗔 𝗠𝗘𝗝𝗢𝗥 𝗢𝗣𝗖𝗜𝗢́𝗡! #AGROtratosBo...</td>\n",
       "      <td>mejor opcion plataforma ideal agronegocios opo...</td>\n",
       "      <td>mejor opcion plataforma ideal agronegocio opor...</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118059</th>\n",
       "      <td>¿Qué marca tiene el mejor servicio postventa d...</td>\n",
       "      <td>marca mejor servicio postventa mercado</td>\n",
       "      <td>marca mejor servicio postventar mercado</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>LABEL_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118060 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "0       Una demanda histórica del feminismo argentino ...   \n",
       "1       ¡Ya dejen de hablar de 'Rompan todo', chiques!...   \n",
       "2       Todxs dicen 'Rompan todo' esto, Santaolalla aq...   \n",
       "3       El mejor periodismo posible se toma 'seco hast...   \n",
       "4       Mayerlín se cruzó con una doctora que corrió c...   \n",
       "...                                                   ...   \n",
       "118055  #AGROnoticias SECTOR AGRÍCOLA BUSCA QUE SUS TI...   \n",
       "118056  #AGROnoticias El país produce 3 mil T de manza...   \n",
       "118057  𝗣𝗟𝗔𝗡𝗜𝗙𝗜𝗖𝗔 𝗧𝗨 𝗦𝗘𝗠𝗔𝗡𝗔 𝗝𝗨𝗡𝗧𝗢 𝗔𝗟 #AGROboletin 𝗖𝗟𝗜𝗠...   \n",
       "118058  ¡𝗣𝗢𝗥𝗤𝗨𝗘́ 𝗦𝗢𝗠𝗢𝗦 𝗟𝗔 𝗠𝗘𝗝𝗢𝗥 𝗢𝗣𝗖𝗜𝗢́𝗡! #AGROtratosBo...   \n",
       "118059  ¿Qué marca tiene el mejor servicio postventa d...   \n",
       "\n",
       "                                              texto_clean  \\\n",
       "0       demanda historica feminismo argentino podria c...   \n",
       "1       dejen hablar rompan chiques mejor discutamos s...   \n",
       "2       todxs dicen rompan santaolalla aquello netflix...   \n",
       "3       mejor periodismo posible toma seco fondo sorbi...   \n",
       "4       mayerlin cruzo doctora corrio gastos internaci...   \n",
       "...                                                   ...   \n",
       "118055  sector agricola busca tierras objeto creditos ...   \n",
       "118056  pais produce mil manzana importa mil argentina...   \n",
       "118057  planifica semana junto clima precios mercados ...   \n",
       "118058  mejor opcion plataforma ideal agronegocios opo...   \n",
       "118059             marca mejor servicio postventa mercado   \n",
       "\n",
       "                                          texto_lem_spacy label_beto  \\\n",
       "0       demanda historico feminismo argentino podria c...    LABEL_1   \n",
       "1       dejar hablar romper chiques mejor discutar sel...    LABEL_1   \n",
       "2       todxs decir romper santaolalla aquel netflix n...    LABEL_1   \n",
       "3       mejor periodismo posible tomar seco fondo sorb...    LABEL_1   \n",
       "4       mayerlin cruzo doctora corrio gastos internaci...    LABEL_1   \n",
       "...                                                   ...        ...   \n",
       "118055  sector agricola buscar tierra objeto creditos ...    LABEL_1   \n",
       "118056  pais producir mil manzana importar mil argenti...    LABEL_1   \n",
       "118057  planificar semana junto clima precio mercado l...    LABEL_1   \n",
       "118058  mejor opcion plataforma ideal agronegocio opor...    LABEL_1   \n",
       "118059            marca mejor servicio postventar mercado    LABEL_0   \n",
       "\n",
       "       label_bert_multi label_bertin label_electra  \n",
       "0               LABEL_1      LABEL_1       LABEL_1  \n",
       "1               LABEL_1      LABEL_1       LABEL_1  \n",
       "2               LABEL_1      LABEL_1       LABEL_1  \n",
       "3               LABEL_1      LABEL_1       LABEL_1  \n",
       "4               LABEL_1      LABEL_1       LABEL_1  \n",
       "...                 ...          ...           ...  \n",
       "118055          LABEL_1      LABEL_1       LABEL_1  \n",
       "118056          LABEL_1      LABEL_1       LABEL_1  \n",
       "118057          LABEL_1      LABEL_1       LABEL_1  \n",
       "118058          LABEL_1      LABEL_1       LABEL_1  \n",
       "118059          LABEL_0      LABEL_0       LABEL_0  \n",
       "\n",
       "[118060 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "145a56de",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics = 5 \n",
    "\n",
    "no_top_words = 10 \n",
    "\n",
    "no_top_documents = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47c34a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF Topics\n",
      "Topic 0:\n",
      "covid (3.57) caso (3.43) nuevo (2.1) bolivia (1.58) contagio (1.37) superar (1.1) positivo (0.72) registrar (0.67) salud (0.52) sed (0.47)\n",
      "Topic 1:\n",
      "mas (1.43) gobierno (1.27) anez (0.84) pedir (0.8) ministro (0.73) candidato (0.71) evo (0.7) elección (0.7) decir (0.66) hacer (0.64)\n",
      "Topic 2:\n",
      "potosi (3.71) presentar (2.37) titular (1.03) cotización (0.7) valor (0.62) clima (0.49) edicion (0.44) portado (0.34) economico (0.34) apertura (0.33)\n",
      "Topic 3:\n",
      "deceso (2.52) recuperado (2.35) reportar (2.31) nuevo (2.04) paciente (1.91) caso (1.78) fallecido (1.66) departamento (1.3) infectado (1.29) contabilizar (1.08)\n",
      "Topic 4:\n",
      "cruz (2.92) santa (2.86) paz (0.5) oruro (0.38) beni (0.33) chuquisaca (0.31) par (0.31) cochabambo (0.29) gobernacion (0.26) salud (0.25)\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "def display_topics(H, W, feature_names, documents, no_top_words, no_top_documents):\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([ (feature_names[i] + \" (\" + str(topic[i].round(2)) + \")\")\n",
    "          for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        top_doc_indices = np.argsort( W[:,topic_idx] )[::-1][0:no_top_documents]\n",
    "        for doc_index in top_doc_indices:\n",
    "            print(str(doc_index))\n",
    "            print(documents[doc_index])\n",
    "\n",
    "# NMF is able to use tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer() #mix min df\n",
    "tfidf = tfidf_vectorizer.fit_transform(df1u['texto_lem_spacy'].to_list())\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Run NMF\n",
    "nmf_model = NMF(n_components=no_topics, random_state=90834).fit(tfidf)\n",
    "nmf_W = nmf_model.transform(tfidf)\n",
    "nmf_H = nmf_model.components_\n",
    "\n",
    "print(\"NMF Topics\")\n",
    "display_topics(nmf_H, nmf_W, tfidf_feature_names, df1u['texto_lem_spacy'].to_list(), no_top_words, no_top_documents)\n",
    "print(\"--------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
